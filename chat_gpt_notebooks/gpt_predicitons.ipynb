{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead939c3-1a87-40cb-9a9e-8f8c41604b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e824631-d448-45b1-b703-a4c2fbab1765",
   "metadata": {},
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98577571-e4bb-435f-bbab-3e2263bcc238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rubq_questions(split='test'):\n",
    "    if os.path.exists('../data/rubq/rubq_test_qa_pairs.json'):\n",
    "        with open(f'../data/rubq/rubq_test_qa_pairs.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "            \n",
    "    with open(f'../data/rubq/rubq_test.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    questions = []\n",
    "    \n",
    "    for item in tqdm(data):\n",
    "        questions.append({\n",
    "                'question': item['question_text'],\n",
    "                'answer': item['answer_text']\n",
    "        })\n",
    "\n",
    "    return questions\n",
    "\n",
    "def get_qald_questions(split='test'):\n",
    "    if os.path.exists('../data/qald/qald_test_qa_pairs.json'):\n",
    "        with open(f'../data/qald/qald_test_qa_pairs.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "        \n",
    "    questions = []\n",
    "\n",
    "    with open(f'../data/qald/qald_{split}.json', 'r') as f:\n",
    "        data = json.load(f)['questions']\n",
    "        \n",
    "    for item in tqdm(data):\n",
    "        \n",
    "        answer_list = []\n",
    "        for a in item['answers']:\n",
    "            if a.get('results'):\n",
    "                for b in a['results']['bindings']:\n",
    "                    if b.get('resultCnt'):\n",
    "                        answer = b['resultCnt']['value']\n",
    "                    else:\n",
    "                        answer = b['result']['value']\n",
    "                    \n",
    "                    match = re.match(r'^https?://www\\.wikidata\\.org/entity/(Q\\d+)$', answer)\n",
    "                    if match:\n",
    "                        answer = match.group(1)\n",
    "                        answer = str(client.get(answer).label)\n",
    "                    \n",
    "                    answer_list.append(answer)\n",
    "        \n",
    "        for q in item['question']:\n",
    "            if q['language'] == 'en':\n",
    "                question = q['string']\n",
    "                \n",
    "        questions.append({\n",
    "            'question': question,\n",
    "            'answer': answer_list\n",
    "        })\n",
    "        \n",
    "    return questions\n",
    "\n",
    "def get_lcquad_questions(split='test'):\n",
    "    if os.path.exists('../data/lcquad/lcquad_test_qa_pairs.json'):\n",
    "        with open(f'../data/lcquad/lcquad_test_qa_pairs.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "            \n",
    "    questions = []\n",
    "    \n",
    "    with open(f'../data/lcquad/lcquad_2_{split}.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "            \n",
    "    for item in tqdm(data):\n",
    "        results = None\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                sparql.setQuery(item['query'])\n",
    "                sparql.setReturnFormat(JSON)\n",
    "                results = sparql.query().convert()\n",
    "                break\n",
    "            except:\n",
    "                sleep(1)\n",
    "                continue\n",
    "        \n",
    "        answer_list = []\n",
    "        if results:\n",
    "            if results.get('results'):\n",
    "                for result in results[\"results\"][\"bindings\"]:\n",
    "                    if result.get('answer'):\n",
    "                        label = result[\"answer\"][\"value\"]\n",
    "                    elif result.get('obj'):\n",
    "                        label = result[\"obj\"][\"value\"]\n",
    "                    answer_list.append(label)\n",
    "            \n",
    "        questions.append({\n",
    "            'question': item['en_question'],\n",
    "            'answer': answer_list,\n",
    "        })\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def get_pat_questions(split='test'):\n",
    "    if os.path.exists('../data/pat/custom_pat_test_qa_pairs.json'):\n",
    "        with open(f'../data/pat/custom_pat_test_qa_pairs.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "            \n",
    "    with open(f'../data/pat/custom_iid_pat_{split}.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    questions = []\n",
    "    \n",
    "    for item in data:\n",
    "        questions.append({\n",
    "            'question': item['question'],\n",
    "            'answer': item['text answers']\n",
    "        })\n",
    "    \n",
    "    return questions\n",
    "\n",
    "def batch_questions(data, batch_size=10):\n",
    "    questions = []\n",
    "    dataset = pd.DataFrame(data)\n",
    "    for start in range(0, len(dataset), batch_size):\n",
    "        batch = dataset.iloc[start:start + batch_size]\n",
    "        questions.append('\\n'.join([f\"{i}) {row.question}\" for i, row in batch.iterrows()]))\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6878572-893c-43e2-bfac-916cd61dc0eb",
   "metadata": {},
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5abca176-8cf5-48a1-a0dd-1d2fdcd47c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import APIClient\n",
    "\n",
    "# api_key = ...\n",
    "client = APIClient(api_key=api_key, max_retries=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f002918-d418-4839-81d1-258cc955c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task_list(dataset, batch_size=60, model_name='gpt-4o', lang='en'):\n",
    "    if lang == 'ru':\n",
    "        system_prompt = ru_system_prompt\n",
    "        prompt = 'Список вопросов:\\n'\n",
    "    elif lang == 'en':\n",
    "        system_prompt = en_system_prompt\n",
    "        prompt = 'Questions:\\n'\n",
    "    \n",
    "    task_list = []\n",
    "    \n",
    "    for i, batch in enumerate(batch_questions(dataset, batch_size)):\n",
    "        content = prompt + batch\n",
    "    \n",
    "        task_list.append({\n",
    "            'task_id': i,\n",
    "            'url': 'https://api.openai.com/v1/chat/completions',\n",
    "            'body': {\n",
    "                'model': model_name,\n",
    "                'messages': [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": content}\n",
    "                ]\n",
    "            }\n",
    "        })\n",
    "        \n",
    "    return task_list\n",
    "\n",
    "def unpack_answer(result):\n",
    "    result_dict = {}\n",
    "    \n",
    "    # Split the data by lines and process each line\n",
    "    for line in result.splitlines():\n",
    "        if not 'ответы' in line.lower() and 'answers' not in line.lower():\n",
    "            try:\n",
    "                key, value = line.split(\") \", 1)  # Split at the first occurrence of \". \"\n",
    "            except:\n",
    "                print(line)\n",
    "            result_dict[int(key)] = value.strip()  # Convert key to int and strip any whitespace from value\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "def save_answer(completed_tasks, dataset_name):\n",
    "    result = {}\n",
    "    for id, complete_task in completed_tasks.items():\n",
    "        result.update(unpack_answer(complete_task[0]['content']))\n",
    "    \n",
    "    with open(f\"../data/gpt_results/{dataset_name}.json\", \"w\",  encoding='utf8') as file:\n",
    "        json.dump(result, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa0e3f41-d7ab-4ee4-bbe9-95e7b2484e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_system_prompt = \"\"\"You are an expert assistant in Open-Domain Question Answering. Answer the following list of questions based on your knowledge and any external materials or sources available to you, adhering to these guidelines:\n",
    "\n",
    "**Guidelines for Answering**:\n",
    "- Provide a concise, factual answer for each question using relevant information from both internal knowledge and external sources.\n",
    "- Treat each question as independent, even though they are listed together.\n",
    "- Each answer should strictly start with the unique ID associated with its question.\n",
    "- Use only singular nouns or names in their base form, avoiding declensions and articles.\n",
    "- Use no punctuation, commas, or periods.\n",
    "- If multiple answers exist, separate them with a special token (e.g., \"|\") and sort them by relevance (the most famous one first).\n",
    "- If the answer is unknown or ambiguous, make a best guess based on common or widely accepted knowledge from available sources, but avoid speculation. Use \"Unknown\" only if no answer can reasonably be provided from any source.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "Questions:\n",
    "1782) What is the largest planet in solar system?\n",
    "78) Who starred in the movie Titanic?\n",
    "9231) When did World War II start?\n",
    "\n",
    "Answers:\n",
    "1782) Jupyter\n",
    "78) Leonardo DiCaprio | Kate Winslet | Billy Zane | Kathy Bates\n",
    "9231) 01.09.1939\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0c3638-1f94-48e6-9318-6a7a966a7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_system_prompt = \"\"\"Вы являетесь экспертом в области ответов на вопросы с открытой областью знаний. Ответьте на следующий список вопросов, основываясь на своих знаниях и любых доступных внешних материалах или источниках, соблюдая эти рекомендации:\n",
    "\n",
    "Рекомендации для ответов:\n",
    "- Предоставьте краткий, фактический ответ на каждый вопрос, используя релевантную информацию из внутренних знаний и внешних источников.\n",
    "- Рассматривайте каждый вопрос как независимый, даже если они перечислены вместе.\n",
    "- Каждый ответ должен строго начинаться с уникального идентификатора, связанного с его вопросом.\n",
    "- Используйте только существительные в единственном числе или имена в их базовой форме, избегая склонений и артиклей.\n",
    "- Не используйте пунктуацию, запятые или точки.\n",
    "- Если существует несколько ответов, разделяйте их специальным символом (например, \"|\") и сортируйте по релевантности (самый известный — первый).\n",
    "- Если ответ неизвестен или неоднозначен, сделайте лучший предположительный вывод, основанный на общих или широко принятых знаниях из доступных источников, но избегайте спекуляций. Используйте \"Неизвестно\" только в том случае, если ответ нельзя разумно предоставить из любого источника.\n",
    "\n",
    "Пример:\n",
    "\n",
    "Вопросы:\n",
    "1782) Какая самая большая планета в Солнечной системе?\n",
    "78) Кто сыграл главную роль в фильме Титаник?\n",
    "9231) Когда началась Вторая мировая война?\n",
    "\n",
    "Ответы: \n",
    "1782) Юпитер\n",
    "78) Леонардо ДиКаприо | Кейт Уинслет | Билли Зейн | Кэти Бейтс\n",
    "9231) 01.09.1939\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b4e3eeb-077c-471c-82f9-c96213df044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лимиты: 499 запросов, 26049 токенов | Токены: 155757:  14%|▏| 1/7 [00:18<01:52, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final success for 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лимиты: 499 запросов, 25441 токенов | Токены: 160585:  29%|▎| 2/7 [00:41<01:45, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final success for 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лимиты: 499 запросов, 25264 токенов | Токены: 165494:  43%|▍| 3/7 [01:04<01:28, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final success for 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лимиты: 499 запросов, 25280 токенов | Токены: 170289:  57%|▌| 4/7 [01:34<01:14, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final success for 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лимиты: 499 запросов, 25359 токенов | Токены: 175083:  71%|▋| 5/7 [01:55<00:47, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final success for 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лимиты: 499 запросов, 25347 токенов | Токены: 180363:  86%|▊| 6/7 [02:16<00:22, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final success for 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лимиты: 499 запросов, 28092 токенов | Токены: 181403: 100%|█| 7/7 [02:18<00:00, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final success for 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATASETS = {\n",
    "    # 'rubq': get_rubq_questions(),\n",
    "    # 'qald': get_qald_questions(),\n",
    "    # 'lcquad': get_lcquad_questions(),\n",
    "    'pat': get_pat_questions()\n",
    "}\n",
    "\n",
    "for name, dataset in DATASETS.items():\n",
    "    if name == 'rubq':\n",
    "        lang = 'ru'\n",
    "    else:\n",
    "        lang = 'en'\n",
    "    task_list = create_task_list(dataset, batch_size=200, lang=lang)\n",
    "    completed_tasks, failed_tasks = await client.process_tasks(task_list, verbose=True)\n",
    "    assert len(failed_tasks) == 0\n",
    "    result = save_answer(completed_tasks, name)\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df['gpt'] = pd.Series(result)\n",
    "    df.to_csv(f'../data/gpt_results/{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a9a95-b685-491a-a474-32879025745c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
